{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Gautam Jain, Jannis Horn \n",
    "\n",
    "%matplotlib notebook\n",
    "import time\n",
    "import os\n",
    "from typing import Tuple\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.use('Agg')\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import torch  \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as func\n",
    "import torch.optim as topt\n",
    "import wandb\n",
    "import cv2\n",
    "import os\n",
    "from torchvision.transforms import ToTensor\n",
    "import torchvision.models as models\n",
    "from torchviz import make_dot\n",
    "from array2gif import write_gif\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "torch.manual_seed( 666 )\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "green = [51.0/255.0, 153.0/255.0, 0]\n",
    "red = [204.0/255.0,0,0]\n",
    "\n",
    "class Logger:\n",
    "    \n",
    "    def __init__( self, prefix ):\n",
    "        self.cur_ep = 0\n",
    "        self.prefix = prefix\n",
    "        \n",
    "    def plot( self, loss, loss_pim, time, epoch=-1 ):\n",
    "        if epoch == -1:\n",
    "            self.cur_ep += 1\n",
    "        else: self.cur_ep = epoch\n",
    "        wandb.log( {\"{}_Loss\".format( self.prefix ): loss,\n",
    "                    \"{}_Time\".format( self.prefix ): time,\n",
    "                    \"{}_Loss Im1\".format( self.prefix ): loss_pim[0],\n",
    "                    \"{}_Loss Im2\".format( self.prefix ): loss_pim[1],\n",
    "                    \"{}_Loss Im3\".format( self.prefix ): loss_pim[2]},\n",
    "                   step=self.cur_ep )\n",
    "        \n",
    "    def plotImages( self, teacher_ims, out_ims, fps=2, epoch=-1 ):\n",
    "        if epoch == -1:\n",
    "            self.cur_ep += 1\n",
    "        else: self.cur_ep = epoch\n",
    "        gifs = []\n",
    "        print(teacher_ims.shape)\n",
    "        for bt_it in range( teacher_ims.shape[0] ):\n",
    "            t_gif = np.stack( [self._drawOutline(im, green, 4) for im in teacher_ims[bt_it,:,:,:,:] ], axis=0 )\n",
    "            o_gif = np.stack( [self._drawOutline(im, green, 4) for im in teacher_ims[bt_it,:3,:,:,:] ]\n",
    "                              +[self._drawOutline(im, red, 4) for im in out_ims[bt_it,3:,:,:,:] ], axis=0 )\n",
    "            gifs.append( self._combineGifs( t_gif, o_gif ) )\n",
    "        self._logGif( \"{}_out\".format( self.prefix ), np.concatenate( gifs, axis=2 ), fps )\n",
    "        print(np.concatenate( gifs, axis=2 ).shape)\n",
    "        \n",
    "    def _drawOutline( self, im, clr, outline_size ):\n",
    "        pad_im = np.empty( [im.shape[0],\n",
    "                            im.shape[1]+2*outline_size,\n",
    "                            im.shape[2]+2*outline_size] )\n",
    "        for ch in range(3):\n",
    "            pad_im[ch,:,:] = np.pad( im[ch,:,:], pad_width=outline_size, mode='constant', constant_values=clr[ch] )\n",
    "        return pad_im\n",
    "    \n",
    "    def _combineGifs( self, gif1, gif2 ):\n",
    "        out = []\n",
    "        for im1, im2 in zip( gif1, gif2 ):\n",
    "            out_im = np.zeros( [3, gif1.shape[-2], gif1.shape[-1]*2+1], dtype=np.uint8 )\n",
    "            out_im[:,:,:gif1.shape[-1]] = (im1*255).astype( np.uint8 )\n",
    "            out_im[:,:,gif1.shape[-1]+1:] = (im2*255).astype( np.uint8 )\n",
    "            out.append( out_im )\n",
    "        return np.stack(out, axis=0)\n",
    "    \n",
    "    def _logGif( self, key, ims, fps ):\n",
    "        wandb.log( {key: wandb.Video( ims, fps=fps )}, \n",
    "                   step=self.cur_ep )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convGRU code taken from: https://github.com/SreenivasVRao/ConvGRU-ConvLSTM-PyTorch/blob/master/convgru.py\n",
    "from convgru import ConvGRU\n",
    "\n",
    "#DSSIM Loss taken from: https://github.com/Po-Hsun-Su/pytorch-ssim/blob/master/pytorch_ssim/__init__.py\n",
    "from dssim import SSIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LadderLayer( nn.Module ):\n",
    "    def __init__( self, w, h, in_channels, out_channels, use_loc_dep ):\n",
    "        super( LadderLayer, self ).__init__()\n",
    "        if not use_loc_dep: self.conv = nn.Conv2d( in_channels, out_channels, (1,1) )\n",
    "        else: self.conv = LocationAwareConv2d( True, False, w, h, in_channels, out_channels, (1,1) )\n",
    "        self.conv_gru3 = ConvGRU( in_channels, out_channels, (3,3), 1, batch_first=True )\n",
    "        self.conv_gru5 = ConvGRU( in_channels, out_channels, (5,5), 1, batch_first=True )\n",
    "        self.conv_gru7 = ConvGRU( in_channels, out_channels, (7,7), 1, batch_first=True )\n",
    "        \n",
    "    def forward( self, x ):\n",
    "        out_l = []\n",
    "        for it in range( x.shape[1] ):\n",
    "            out_l.append( self.conv( x[:,it,:,:,:] ) )\n",
    "        out = torch.stack( out_l, dim=1 )\n",
    "        out3,_ = self.conv_gru3( x )\n",
    "        out5,_ = self.conv_gru5( x )\n",
    "        out7,_ = self.conv_gru7( x )\n",
    "        return torch.cat( [out, out3[0], out5[0], out7[0]], dim=2 )\n",
    "        \n",
    "        \n",
    "class ReconstructionLayer( nn.Module ):\n",
    "    def __init__( self, in_channels, use_btnorm ):\n",
    "        super( ReconstructionLayer, self ).__init__()\n",
    "        if not use_btnorm: self.relu = nn.ReLU()\n",
    "        else: self.relu = nn.Sequential( nn.ReLU(), nn.BatchNorm2d( in_channels ) )\n",
    "        self.conv1 = nn.Conv2d( in_channels, 1024, (3,3), padding=1 )\n",
    "        self.shuffle = nn.PixelShuffle( 2 )\n",
    "        self.conv2 = nn.Conv2d( 256, 64, (3,3), padding=1 )\n",
    "        \n",
    "    def forward( self, x ):\n",
    "        out = self.relu( x )\n",
    "        out = self.conv1( out )\n",
    "        out = self.shuffle( out )\n",
    "        out = self.conv2( out )\n",
    "        return out\n",
    "        \n",
    "        \n",
    "class LocationAwareConv2d(torch.nn.Conv2d):\n",
    "    def __init__(self,locationAware,gradient,w,h,in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True):\n",
    "        super().__init__(in_channels, out_channels, kernel_size, stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n",
    "        if locationAware:\n",
    "            self.locationBias=torch.nn.Parameter(torch.zeros(w,h,3))\n",
    "            self.locationEncode=torch.autograd.Variable(torch.ones(w,h,3))\n",
    "            if gradient:\n",
    "                for i in range(w):\n",
    "                    self.locationEncode[i,:,1]=self.locationEncode[:,i,0]=i/float(w-1)\n",
    "        \n",
    "        self.up=torch.nn.Upsample(size=(w,h), mode='bilinear', align_corners=False)\n",
    "        self.w=w\n",
    "        self.h=h\n",
    "        self.locationAware=locationAware\n",
    "        \n",
    "    def forward(self,inputs):\n",
    "        if self.locationAware:\n",
    "            if self.locationBias.device != inputs.device:\n",
    "                self.locationBias=self.locationBias.to(inputs.get_device())\n",
    "            if self.locationEncode.device != inputs.device:\n",
    "                self.locationEncode=self.locationEncode.to(inputs.get_device())\n",
    "            b=self.locationBias*self.locationEncode\n",
    "        convRes=super().forward(inputs)\n",
    "        if convRes.shape[2]!=self.w and convRes.shape[3]!=self.h:\n",
    "            convRes=self.up(convRes)\n",
    "        if self.locationAware:\n",
    "            return convRes+b[:,:,0]+b[:,:,1]+b[:,:,2]\n",
    "        else:\n",
    "            return convRes\n",
    "        \n",
    "    def  __str__( self ):\n",
    "        return( \"LocationAware{}, LocAware={}, gradient={}\".format( super().__str__(), self.locationAware, self.Gradient ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 6, 3, 320, 224])\n",
      "tensor(339.2009, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "PredictionModel(\n",
      "  (resnet18): ResNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      "  )\n",
      "  (ladders): ModuleDict(\n",
      "    (ladder1): LadderLayer(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (conv_gru3): ConvGRU(\n",
      "        (cell_list): ModuleList(\n",
      "          (0): ConvGRUCell(\n",
      "            (update_gate): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (reset_gate): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (out_gate): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (conv_gru5): ConvGRU(\n",
      "        (cell_list): ModuleList(\n",
      "          (0): ConvGRUCell(\n",
      "            (update_gate): Conv2d(128, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "            (reset_gate): Conv2d(128, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "            (out_gate): Conv2d(128, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (conv_gru7): ConvGRU(\n",
      "        (cell_list): ModuleList(\n",
      "          (0): ConvGRUCell(\n",
      "            (update_gate): Conv2d(128, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "            (reset_gate): Conv2d(128, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "            (out_gate): Conv2d(128, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ladder2): LadderLayer(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (conv_gru3): ConvGRU(\n",
      "        (cell_list): ModuleList(\n",
      "          (0): ConvGRUCell(\n",
      "            (update_gate): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (reset_gate): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (out_gate): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (conv_gru5): ConvGRU(\n",
      "        (cell_list): ModuleList(\n",
      "          (0): ConvGRUCell(\n",
      "            (update_gate): Conv2d(128, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "            (reset_gate): Conv2d(128, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "            (out_gate): Conv2d(128, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (conv_gru7): ConvGRU(\n",
      "        (cell_list): ModuleList(\n",
      "          (0): ConvGRUCell(\n",
      "            (update_gate): Conv2d(128, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "            (reset_gate): Conv2d(128, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "            (out_gate): Conv2d(128, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ladder3): LadderLayer(\n",
      "      (conv): LocationAwareConv2d(\n",
      "        128, 64, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (up): Upsample(size=(40, 28), mode=bilinear)\n",
      "      )\n",
      "      (conv_gru3): ConvGRU(\n",
      "        (cell_list): ModuleList(\n",
      "          (0): ConvGRUCell(\n",
      "            (update_gate): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (reset_gate): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (out_gate): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (conv_gru5): ConvGRU(\n",
      "        (cell_list): ModuleList(\n",
      "          (0): ConvGRUCell(\n",
      "            (update_gate): Conv2d(192, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "            (reset_gate): Conv2d(192, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "            (out_gate): Conv2d(192, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (conv_gru7): ConvGRU(\n",
      "        (cell_list): ModuleList(\n",
      "          (0): ConvGRUCell(\n",
      "            (update_gate): Conv2d(192, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "            (reset_gate): Conv2d(192, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "            (out_gate): Conv2d(192, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ladder4): LadderLayer(\n",
      "      (conv): LocationAwareConv2d(\n",
      "        256, 64, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (up): Upsample(size=(20, 14), mode=bilinear)\n",
      "      )\n",
      "      (conv_gru3): ConvGRU(\n",
      "        (cell_list): ModuleList(\n",
      "          (0): ConvGRUCell(\n",
      "            (update_gate): Conv2d(320, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (reset_gate): Conv2d(320, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (out_gate): Conv2d(320, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (conv_gru5): ConvGRU(\n",
      "        (cell_list): ModuleList(\n",
      "          (0): ConvGRUCell(\n",
      "            (update_gate): Conv2d(320, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "            (reset_gate): Conv2d(320, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "            (out_gate): Conv2d(320, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (conv_gru7): ConvGRU(\n",
      "        (cell_list): ModuleList(\n",
      "          (0): ConvGRUCell(\n",
      "            (update_gate): Conv2d(320, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "            (reset_gate): Conv2d(320, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "            (out_gate): Conv2d(320, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (recons): ModuleDict(\n",
      "    (recon1): ReconstructionLayer(\n",
      "      (relu): Sequential(\n",
      "        (0): ReLU()\n",
      "        (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (conv1): Conv2d(320, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (shuffle): PixelShuffle(upscale_factor=2)\n",
      "      (conv2): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (recon2): ReconstructionLayer(\n",
      "      (relu): Sequential(\n",
      "        (0): ReLU()\n",
      "        (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (conv1): Conv2d(320, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (shuffle): PixelShuffle(upscale_factor=2)\n",
      "      (conv2): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (recon3): ReconstructionLayer(\n",
      "      (relu): Sequential(\n",
      "        (0): ReLU()\n",
      "        (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (conv1): Conv2d(320, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (shuffle): PixelShuffle(upscale_factor=2)\n",
      "      (conv2): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (recon4): ReconstructionLayer(\n",
      "      (relu): ReLU()\n",
      "      (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (shuffle): PixelShuffle(upscale_factor=2)\n",
      "      (conv2): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (out_conv): Conv2d(320, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (out_shuffle): PixelShuffle(upscale_factor=2)\n",
      "  (out_act): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class PredictionModel( nn.Module ):\n",
    "    \n",
    "    def __init__( self, w, h ):\n",
    "        super( PredictionModel, self ).__init__()\n",
    "        self.resnet18 = models.resnet18( pretrained=True )\n",
    "        for param in self.resnet18.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.ladders = nn.ModuleDict( {\n",
    "            \"ladder1\": LadderLayer( int(w/2), int(h/2), 64, 64, False ),\n",
    "            \"ladder2\": LadderLayer( int(w/4), int(h/4), 64, 64, False ),\n",
    "            \"ladder3\": LadderLayer( int(w/8), int(h/8), 128, 64, True ),\n",
    "            \"ladder4\": LadderLayer( int(w/16), int(h/16), 256, 64, True ) \n",
    "        } )\n",
    "        self.recons = nn.ModuleDict( {\n",
    "            \"recon1\": ReconstructionLayer( 64*5, True ),\n",
    "            \"recon2\": ReconstructionLayer( 64*5, True ),\n",
    "            \"recon3\": ReconstructionLayer( 64*5, True ),\n",
    "            \"recon4\": ReconstructionLayer( 512, False )\n",
    "        } )\n",
    "        self.out_conv = nn.Conv2d( 320, 12, (1,1) )\n",
    "        self.out_shuffle = nn.PixelShuffle( 2 )\n",
    "        self.out_act = nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "    def getResnetOutputs( self, x ):\n",
    "        inp_c = self.resnet18.conv1( x )\n",
    "        inp = self.resnet18.bn1( inp_c )\n",
    "        inp = self.resnet18.relu( inp )\n",
    "        inp = self.resnet18.maxpool( inp )\n",
    "        res_out1 = self.resnet18.layer1( inp )\n",
    "        res_out2 = self.resnet18.layer2( res_out1 )\n",
    "        res_out3 = self.resnet18.layer3( res_out2 )\n",
    "        res_out4 = self.resnet18.layer4( res_out3 )\n",
    "        return ( inp_c, res_out1, res_out2, res_out3, res_out4 )\n",
    "    \n",
    "    def getReconstructionOutput( self, res_x, rec_x, l_it ):\n",
    "        l_out = self.ladders[\"ladder{}\".format(l_it)]( res_x )\n",
    "        r_out_l = []\n",
    "        for it in range( rec_x.shape[1] ):\n",
    "            r_out_l.append( self.recons[\"recon{}\".format(l_it)]( rec_x[:,it,:,:,:] ) )\n",
    "        r_out = torch.stack( r_out_l, dim=1 )\n",
    "        out = torch.cat( [r_out, l_out], dim=2 )\n",
    "        return out\n",
    "    \n",
    "    def getL2Norm( self ):\n",
    "        out = torch.tensor(0.0).to( self.out_conv.weight.device )\n",
    "        for param in self.ladders.parameters():\n",
    "            out += torch.norm( param, 2 )\n",
    "        for param in self.recons.parameters():\n",
    "            out += torch.norm( param, 2 )\n",
    "        out += torch.norm( self.out_conv.weight, 2 )\n",
    "        return out\n",
    "        \n",
    "    def forward( self, x ):\n",
    "        res_out = []\n",
    "        for it in range( x.shape[1] ):\n",
    "            res_out.append( self.getResnetOutputs( x[:,it,:,:,:] ) )\n",
    "        res_0 = torch.stack( [r[0] for r in res_out], dim=1 )\n",
    "        res_1 = torch.stack( [r[1] for r in res_out], dim=1 )\n",
    "        res_2 = torch.stack( [r[2] for r in res_out], dim=1 )\n",
    "        res_3 = torch.stack( [r[3] for r in res_out], dim=1 )\n",
    "        res_4 = torch.stack( [r[4] for r in res_out], dim=1 )\n",
    "        out = self.getReconstructionOutput( res_3, res_4, 4 )\n",
    "        out = self.getReconstructionOutput( res_2, out, 3 )\n",
    "        out = self.getReconstructionOutput( res_1, out, 2 )\n",
    "        out = self.getReconstructionOutput( res_0, out, 1 )\n",
    "        out_l = []\n",
    "        for it in range( x.shape[1] ):\n",
    "            out_f = self.out_conv(out[:,it,:,:,:])\n",
    "            out_f = self.out_shuffle( out_f )\n",
    "            out_f = self.out_act( out_f )\n",
    "            out_l.append( out_f )\n",
    "            \n",
    "        return torch.stack( out_l, dim=1 )\n",
    "        \n",
    "\n",
    "model = PredictionModel(320,224)\n",
    "#print(model.ladders[\"ladder1\"], model.recons[\"recon1\"])\n",
    "inp = torch.rand( 2,6,3,320,224 ).to( device )\n",
    "model = model.to( device )\n",
    "out = model(inp)\n",
    "print( out.shape )\n",
    "print( model.getL2Norm() )\n",
    "print(model)\n",
    "#make_dot( out, params=dict(model.named_parameters()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper params\n",
    "name = \"MNIST_Base\"\n",
    "lr = 1e-5\n",
    "l2_lambda = 1e-15\n",
    "num_epochs = 10\n",
    "ssim_win_size = 11\n",
    "bt_size = 32\n",
    "\n",
    "split_per = 0.8\n",
    "seq_length = 6\n",
    "trunc_ds = 0\n",
    "ld_threads = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "875 125 [  0 125 250 375 500 625 750]\n",
      "3500 1750\n"
     ]
    }
   ],
   "source": [
    "# Dataset\n",
    "\n",
    "def loadMovingMNIST( path ):\n",
    "    data = np.load( path )\n",
    "    dt_list = []\n",
    "    for seq_it in range( data.shape[1] ):\n",
    "        seq = data[:,seq_it,:,:].copy()\n",
    "        seq = np.repeat( seq[:,np.newaxis,:,:], 3, axis=1 )\n",
    "        dt_list.append( seq )\n",
    "    del data\n",
    "    return dt_list\n",
    "\n",
    "def splitSet( data, split_per ):\n",
    "    split_it = int( np.round( len(data) *split_per ) )\n",
    "    return data[0:split_it], data[split_it:]\n",
    "    \n",
    "    \n",
    "class SequenceDataset:\n",
    "    def __init__( self, data, seq_length ):\n",
    "        self.data = data\n",
    "        self.width = self.data[0].shape[-2]\n",
    "        self.height = self.data[0].shape[-1]\n",
    "        self.seq_length = seq_length\n",
    "        self._indexSequences()\n",
    "        \n",
    "    def _indexSequences( self ):\n",
    "        last_idx = 0\n",
    "        idxs = []\n",
    "        for seq in self.data:\n",
    "            next_idx = max( 0, seq.shape[0] -self.seq_length ) +last_idx\n",
    "            idxs.append( next_idx )\n",
    "            last_idx = next_idx\n",
    "        self.len = next_idx\n",
    "        self.idx_shape = int(np.ceil( np.sqrt( len(idxs) ) ))\n",
    "        idxs += [0]*(np.square(self.idx_shape) -len(idxs))\n",
    "        self.idx = np.array( idxs ).reshape( (self.idx_shape, self.idx_shape) )\n",
    "        self.idx_map = self.idx.max( axis=1 )\n",
    "        \n",
    "        \n",
    "    def __getitem__( self, idx ):\n",
    "        d0 = np.argmax( self.idx_map > idx )\n",
    "        d1 = np.argmax( self.idx[d0,:] > idx )\n",
    "        seq_idx = d0*self.idx_shape +d1\n",
    "        seq_start_it = idx+self.data[seq_idx].shape[0] -self.idx[d0,d1]-self.seq_length \n",
    "        #print( seq_start_it, seq_start_it +self.seq_length )\n",
    "        out = self.data[seq_idx][seq_start_it:seq_start_it+self.seq_length+1,:,:,:]\n",
    "        out = out.astype( np.float32 ) /255\n",
    "        return torch.tensor( out )\n",
    "        \n",
    "        \n",
    "    def __len__( self ):\n",
    "        return self.len\n",
    "    \n",
    "        \n",
    "        \n",
    "if \"MNIST\" in name or \"mnist\" in name:\n",
    "    data = loadMovingMNIST( \"project/data/mnist_test_seq.npy\" )\n",
    "    tr_data, ts_data = splitSet( data, split_per )\n",
    "    if trunc_ds > 0:\n",
    "        ts_trunc = int( (1-split_per)*trunc_ds )\n",
    "        tr_set = SequenceDataset( tr_data[:trunc_ds], seq_length )\n",
    "        ts_set = SequenceDataset( ts_data[:ts_trunc], seq_length )\n",
    "    else:\n",
    "        tr_set, ts_set = SequenceDataset( tr_data, seq_length ), SequenceDataset( ts_data, seq_length )\n",
    "elif \"Robot\" in name or \"robot\" in name:\n",
    "    pass\n",
    "train_loader = torch.utils.data.DataLoader( dataset=tr_set, \n",
    "                                            batch_size=bt_size, \n",
    "                                            shuffle=True,\n",
    "                                            num_workers=ld_threads)\n",
    "test_loader = torch.utils.data.DataLoader( dataset=ts_set, \n",
    "                                           batch_size=bt_size, \n",
    "                                           shuffle=False,\n",
    "                                           num_workers=ld_threads )\n",
    "\n",
    "n_im_out = 8\n",
    "out_inc = int(len( test_loader )/(n_im_out-1))\n",
    "out_its = np.arange( 0, len( test_loader ), out_inc )[:n_im_out]\n",
    "tests_pb = 2\n",
    "test_inc = int(len( train_loader )/(tests_pb))\n",
    "print(len(test_loader), out_inc, out_its)\n",
    "print(len(train_loader), test_inc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.20 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.12<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">MNIST_Base</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/cudavisionlab/project_predictvideo\" target=\"_blank\">https://wandb.ai/cudavisionlab/project_predictvideo</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/cudavisionlab/project_predictvideo/runs/jecqm91o\" target=\"_blank\">https://wandb.ai/cudavisionlab/project_predictvideo/runs/jecqm91o</a><br/>\n",
       "                Run data is saved locally in <code>/home/user/horn/Documents/Cuda-vision-Lab/wandb/run-20210226_161054-jecqm91o</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Testing 870/875: Loss: 0.30414952135634154\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Test Loss 0.30399503087997437\r",
      "(7, 6, 3, 64, 64)\n",
      "MoviePy - Building file /tmp/tmpj3elzpzfwandb-media/2pjcegdq.gif with imageio.\n",
      "(6, 3, 504, 145)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Testing 870/875: Loss: 0.18375325411900706\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Test Loss 0.1836458603313991\r",
      "(7, 6, 3, 64, 64)\n",
      "MoviePy - Building file /tmp/tmpj3elzpzfwandb-media/lgds3rio.gif with imageio.\n",
      "(6, 3, 504, 145)\n",
      "Epoch 1: Loss 0.045911465082849774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 1590/3500: Loss: 0.17724590897560123\r"
     ]
    }
   ],
   "source": [
    "model = PredictionModel(tr_set.width,tr_set.height)\n",
    "model = model.to( device )\n",
    "#scheduler = \n",
    "optimizer = topt.Adam( model.parameters(), lr=lr )\n",
    "loss_func = SSIM( window_size=ssim_win_size ).to( device )\n",
    "run = wandb.init( project=\"project_predictvideo\", entity=\"cudavisionlab\", name=name, reinit=True )\n",
    "tr_logger = Logger( \"train\" )\n",
    "ts_logger = Logger( \"test\" )\n",
    "\n",
    "with run:\n",
    "    wandb.config.lr = lr\n",
    "    wandb.config.l2 = l2_lambda\n",
    "    wandb.config.ssim_ws = ssim_win_size\n",
    "    for epoch in range( num_epochs ):\n",
    "        st_pt = time.time()\n",
    "        bt_loss = np.array( 0.0 )\n",
    "        run_loss = 0.0\n",
    "        losses = np.zeros( 3 )\n",
    "        model.train()\n",
    "        for tr_it, seq in enumerate( train_loader ):        \n",
    "            seq = seq.to( device )\n",
    "            optimizer.zero_grad()\n",
    "            out = model( seq[:,:-1,:,:,:] )\n",
    "            \n",
    "            loss = torch.tensor(0.0).to( device )\n",
    "            for im_it in range( 3,6 ):\n",
    "                cur_loss = (1-loss_func( seq[:,im_it+1,:,:,:], out[:,im_it,:,:,:] ))/2\n",
    "                loss += cur_loss\n",
    "                losses[im_it-3] += cur_loss.detach().clone().cpu().item()\n",
    "            loss += model.getL2Norm() *l2_lambda\n",
    "            loss.backward()\n",
    "            loss_cpu = loss.detach().clone().cpu().item()\n",
    "            bt_loss += loss_cpu\n",
    "            run_loss += loss_cpu\n",
    "            optimizer.step()\n",
    "            if (tr_it+1)%10 == 0: \n",
    "                print( \"Epoch {}: {}/{}: Loss: {}\".format( epoch+1, tr_it+1, len( train_loader ), bt_loss/(tr_it+1) ), end='\\r' )\n",
    "                if (tr_it+1)%100 == 0:\n",
    "                    tr_logger.plot( run_loss /100, losses /(tr_it+1), time.time() -st_pt )\n",
    "                    st_pt = time.time()\n",
    "                    run_loss = 0.0\n",
    "            \n",
    "            if (tr_it+1)%test_inc == 0: \n",
    "                ts_st_pt = time.time()\n",
    "                bt_loss = np.array( 0.0 )\n",
    "                losses = np.zeros( 3 )\n",
    "                model.eval()\n",
    "                seq_real = []\n",
    "                seq_out = []\n",
    "                for ts_it, seq in enumerate( test_loader ):  \n",
    "                    seq = seq.to( device )\n",
    "                    out = model( seq[:,:-1,:,:,:] )\n",
    "\n",
    "                    loss = torch.tensor(0.0).to( device )\n",
    "                    for im_it in range( 3,6 ):\n",
    "                        cur_loss = (1-loss_func( seq[:,im_it+1,:,:,:], out[:,im_it,:,:,:] ))/2\n",
    "                        loss += cur_loss\n",
    "                        losses[im_it-3] += cur_loss.detach().clone().cpu().item()\n",
    "                    bt_loss += loss.detach().clone().cpu().item()\n",
    "                    if (ts_it+1)%10 == 0: \n",
    "                        print( \"Epoch {}: Testing {}/{}: Loss: {}\".format( epoch+1, ts_it+1, len( test_loader ), bt_loss/(ts_it+1) ), end='\\r' )\n",
    "                    if ts_it in out_its:\n",
    "                        seq_real.append( seq[0,1:,:,:,:].cpu().numpy() )\n",
    "                        seq_out.append( out[0,:,:,:,:].detach().cpu().numpy() )\n",
    "\n",
    "                print( \"Epoch {}: Test Loss {}\".format( epoch+1, bt_loss /len(test_loader) ), end='\\r' )    \n",
    "                ts_logger.plot( bt_loss /len(test_loader), losses /len(test_loader), time.time() -ts_st_pt, epoch=tr_logger.cur_ep )\n",
    "                ts_logger.plotImages( np.stack( seq_real, axis=0 ), \n",
    "                                      np.stack( seq_out, axis=0 ), \n",
    "                                      epoch=tr_logger.cur_ep )\n",
    "            \n",
    "        tr_logger.plot( bt_loss /len(train_loader), losses /len(train_loader), time.time() -st_pt )\n",
    "        print( \"Epoch {}: Loss {}\".format( epoch+1, bt_loss /len(train_loader) ) )\n",
    "\n",
    "torch.save(model.state_dict(), \"./project/nets/{}\".format( name ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
